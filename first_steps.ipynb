{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important note: \n",
    "\n",
    "* After finishing this project the API_KEY shown here won't be working anymore. Having said that, if you try to use this code in future, may you wish to generate a valid key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to set your key as an enviroment variable that you can afterward retrieve it. \n",
    "\n",
    "* To create an enviroment variable: \n",
    "` os.environ['name of the env. variable'] = 'key' `\n",
    "\n",
    "* To retrieve the variable\n",
    "`os.getenv('name of the variable')`\n",
    "\n",
    "For the example below, I am going to create a variable called 'OPENAI_API_KEY' and inform the 'key' I created for testing. \n",
    "!Notice, it is important that once you've created this key and settled your environment variable, you delete the key from your code. So it won't be easily seen and available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='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'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are alternatives solution to avoid showing the API key in your code. \n",
    "\n",
    "* Solution 1: \n",
    "> Using the library 'getpass' you can make the code ask you about the key.\n",
    "\n",
    "```\n",
    "import getpass\n",
    "key = getpass.getpass('Paste your API key:')\n",
    "openai.apikey = key\n",
    "```\n",
    "\n",
    "* Solution 2: \n",
    "> Save your api key into a file and call the correct opeanai module to read it from there\n",
    "```\n",
    "openai.api_key = open('key.txt').read().strip('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI model is a software program that uses specific ML and DL algo and has bein trained on a set of data to perform specific tasks. \n",
    "OPENAI offers a family of models with different capabilities. Each model can be customized by 'fine-tuning' it. It means you can adjust things to have your flavour. \n",
    "\n",
    "!Be sure to have a look at the set of models provided by OPEN_AI and its functionalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prompt \n",
    "\n",
    "THe prompt is a piece of text of instructions that is given to an AI model to guide it in generating a specific output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing\n",
    "\n",
    "Currently the usage of chatGPT isn't free of charge. Information about how it costs may be found at `openai.com/pricing`\n",
    "\n",
    "Here is an example of the price (dating 26th Jan 2024): \n",
    "> gpt-3.5-turbo-1106\t$0.0010 / 1K tokens\t$0.0020 / 1K tokens\n",
    "\n",
    "* Fining-tune models \n",
    "> gpt-3.5-turbo\t$0.0080 / 1K tokens\t$0.0030 / 1K tokens\t$0.0060 / 1K tokens\n",
    "\n",
    "1000 tokens = 750 words (english based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens \n",
    "\n",
    "Each AI model has its own limit with regarding the number of tokens used to request/retrieve information. \n",
    "For example, the model we'll be using here is currently tighten to 4096 tokens. \n",
    "\n",
    "> `gpt-3.5-turbo 4,096 tokens`\n",
    "\n",
    "* What are tokens? \n",
    "\n",
    "> Tokens are peices of words, before the API processes the prompt, the input is browken down into tokens. \n",
    "\n",
    "> Tokens can be words or just chuncks of characters.\n",
    "\n",
    "> 1 token is approximately 4 characters or 0.75 words for English text. \n",
    "\n",
    "\n",
    "It is important to be aware of how tokens are computized. There are many ways you can see how many tokens your text provides to the API. \n",
    "\n",
    "1. Let's assume you have a response. Just type the command `print(response.usage)`\n",
    "2. You can use the OpenAI python library called `tiktoken`\n",
    "3. Utilize the `tokenizer` also from OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chat.completions\n",
    "\n",
    "Let's discuss some of the arguments of the function `client.chat.completions.create()`\n",
    "\n",
    "* model: indicates the model type you want to use \n",
    "\n",
    "* messages: it is a list of dictionaries. Each dictionary has two properties, role and content.\n",
    "- The roles are 'system', 'user', and 'assistant'\n",
    ">  message = [{system}, {user}, {assistant}]\n",
    ">  message = [{role:content}, {role:content}, {role:content}]\n",
    "- System: It helps set the behavior of the assistant, you can extract the model to play a specific role \n",
    "- User: It is the prompt for what you ask the assistante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Indulge in frozen bliss!\"\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=32, total_tokens=48)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Get a list of all available models\n",
    "# A paid account has a more extensive list of available models\n",
    "def print_available_models():\n",
    "    cm = client.models.list()\n",
    "    for models in cm: \n",
    "        print(models)\n",
    "\n",
    "# Notice that it explains and ends the explanation with a question\n",
    "system_role_content1 = 'You explain concepts in depth using simple terms, and you give examples to help people learn. At the end of each explanation you ask a question to check for understanding'\n",
    "system_role_content2 = 'You are a concise assistant. You reply briefly with no elaboration'\n",
    "\n",
    "# Setting the personality of the model and giving specific instructions on how to response some types of response and also injecting instructions into the model's reponse\n",
    "system_role_content3 = 'You reply in the style of Yoda character from Star Wars'\n",
    "\n",
    "# To create a gpt request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo', \n",
    "    messages=[\n",
    "        {'role': 'system', 'content': system_role_content2},\n",
    "        {'role': 'system', 'content': 'Write a short article about coffee.'}, \n",
    "    ],\n",
    "    # it controls how creative and random the model is (openai models are non deterministic, i.e., same input gives diff. results )\n",
    "    # large temperature -> more deterministic and more predictable results. (can be set between 0-2, default = 1.0)\n",
    "    # low temperature   -> a few answers or even a single one to generate ideas or a complete story. \n",
    "    # large temperature -> diverse but it has a probability to hallucination.\n",
    "    temperature=1,\n",
    "    # more updated versions allows a parameter for predictable outputs\n",
    "    # seed = integer -> it retrieves the system_fingertype of where the answer was generated. If the same system_fingerprint is used across different API request calls, it is likely you gonna receive different answers. \n",
    "    # by setting 'seed' you increase the deterministic parameter so you get the same answer acrros different api calls.\n",
    "    # seed='1234'\n",
    "    \n",
    "    # Nucleous sampling. It controls how much the model focus on the most likely completions. \n",
    "    # For example: 0.2 -> only the tokens comprizing on the top 20% probability mass (most commom tokens) are taken into consideration. \n",
    "    # For example: 1.0 -> means use all tokens on the vocabulary \n",
    "    # You should avoid use top_p and temperature simultaneously. \n",
    "    # top_p=0.2,\n",
    "    \n",
    "    # be careful with this one because it can cut off the final answer for the user. \n",
    "    # max_tokens=\n",
    "    \n",
    "    # Set the total number of different answers\n",
    "    # n=2\n",
    "    \n",
    "    # Used to make the model stop . For example: one line answer means stop when making a breaking line '\\n'\n",
    "    # it can also be used a list stop=[';', '.', \"\\n\"]. ps: some symbols are very useful if you are generating a SELECT SQL query output\n",
    "    # stop='\\n'\n",
    "    \n",
    "    # frequency_penalty=0 # is by defaul 0. Can be set between -2 and +2. Lower value make the model repeat itself more often. It controls the quality of the answers.\n",
    "    # presence_penalty=0 # is by defaul 0 and [-2,+2] that encorages the model to use a diverse range of words that generates; dont just focus into the most commom words, but use the other words of the dictionaries too.\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Indulge in Frozen Bliss.\"\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=32, total_tokens=48)\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[1].message.content)\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model='gpt-3.5-turbo', \n",
    "messages=[\n",
    "    {'role': 'system', 'content': system_role_content2},\n",
    "    {'role': 'system', 'content': 'Write one sentecne review of 1984 by George Orwell'}, \n",
    "],\n",
    "```\n",
    "\n",
    "Answer with h_top=1:\n",
    " \n",
    "\"1984\" by George Orwell is a chilling and thought-provoking dystopian novel that explores the dangers of totalitarianism and the erosion of individual freedom.\n",
    "> CompletionUsage(completion_tokens=32, prompt_tokens=37, total_tokens=69)\n",
    "\n",
    "Answer with h_top=0.2:\n",
    "\n",
    "\"1984\" by George Orwell is a chilling and thought-provoking dystopian novel that remains relevant today.\n",
    "> CompletionUsage(completion_tokens=23, prompt_tokens=37, total_tokens=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How GPT Models work? \n",
    "### Highlights of the important aspects (A very high overview perspective)\n",
    "\n",
    "Open AI's GPT family of models are all LLMs (Large Language Models)\n",
    "\n",
    "An LLM is a type of AI that can generate and understand human language. \n",
    "\n",
    "A large ammount of text is used to traning and allow the machine to learn our language. \n",
    "\n",
    "LLMs key components: \n",
    "1. `Self-Attention Mechanism` - allos the model to fpocus on the most relevant part of the input text when generating or understanding language \n",
    "\n",
    "2. `Reinforcement Learning from Human feedback (RLHF)` - involves traning the model to generate resposnes that are informative , factual, engaging, and relevant to the conversations context. \n",
    "\n",
    "`GPT = Generative Pre-trained transformer `\n",
    "\n",
    "* `Generative` = the model is designed to generate new output based on the input it is given\n",
    "\n",
    "* `Pre-trained` = the model was trained on a large corpus of data before being fine-tuned on a specific task \n",
    "\n",
    "* `Transformer` = which is a type of neural network that utilizes self-attention mechanicsm to evaluate the significance of various input tokens when generating output. \n",
    "\n",
    "LLMs - huge quantities of text data and infer relationships between words within the text; enhance their capabilites as the size of their input datasets and parameter space increase\n",
    "\n",
    "## LLMs Issues and Limitations \n",
    "\n",
    "* Capability - accuracy, fluency, creativity, adaptability, and robustness\n",
    "* Alignment  - to what extent the model's goals and behavior align with human values and expectations\n",
    "\n",
    "LLMs are prone to misalignment. This misalignment comes from probability. \n",
    "* Model hallucinations, \n",
    "* lack of interpratbility\n",
    "* generating biased or toxic output. \n",
    "\n",
    "GPT3, 3.5-Turbo, 4, are generative modes with the following core techniques: \n",
    "* Next-token prediction\n",
    "This defines the words to be said in a sequence in a human like format. Given a sequence of words as input, which word would be the most probable one? (that makes it sound correct, and human)\n",
    "\n",
    "* Masked-Language modeling\n",
    "It is a variant of the next-token prediction. \n",
    "\n",
    "> `Interesting to read` \n",
    "Paper: Training language models to follow intructions with human feedback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "Prompt engineering is the art of crafting intructions for LLMs to get desired responses. \n",
    "\n",
    "`Tasks -> Provide Contexts -> Provides desirable outcomes`\n",
    "\n",
    "## Best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "os.environ['OPENAI_API_KEY']='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'\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_chat_completion(\n",
    "    user_prompt, \n",
    "    system_role='You are a helpful assistant',\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=1\n",
    "    ):\n",
    "    \n",
    "    messages=[\n",
    "        {'role': 'system', 'content': system_role},\n",
    "        {'role': 'user',   'content': user_prompt}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages, \n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average distance from Earth to Mars is approximately 225 million kilometers (140 million miles) when the two planets are at their closest approach. However, this distance can vary greatly depending on the positions in their orbits.\n"
     ]
    }
   ],
   "source": [
    "response=get_chat_completion('what is the distance to Mars in km?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guidelines for prompting\n",
    "\n",
    "Clear, specific, and provides LLMs with sufficient context and time to generate the desired output\n",
    "\n",
    "1. Use the latest model\n",
    "2. Write clear and specific instructions (most important). \n",
    "    > clear doesnt mean short. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Tactic 1`: Position Instruction clearly with delimiters\n",
    "\n",
    "*Put instructions at the beginning of the prompt,* each on their own line, an use delimiters to clearly indicate distinct parts of the prompt. \n",
    "\n",
    "**Delimiters**: triple backticks ```, triple quotes\"\"\", or curly braces{}\n",
    "\n",
    "See the example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Engineering ist eine neue Disziplin zur Entwicklung und Optimierung von Anweisungen, um Sprachmodelle (LMs) effizient für eine Vielzahl von Anwendungen und Forschungsthemen zu nutzen.\n"
     ]
    }
   ],
   "source": [
    "text= ''' \n",
    "Prompt engineering is a new discipline for developing and optimizing prompts to efficently\n",
    "use language models (LMs) for a wide variety of applications and research topics.\n",
    "'''\n",
    "\n",
    "prompt = f''' \n",
    "Translate the text delimited by triple backticks from English to German.\n",
    "```{text}```\n",
    "'''\n",
    "\n",
    "response = get_chat_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Tactic 2`: Provide Detailed Instructions for the Context\n",
    "\n",
    "Be specific, descriptve and as detailed as possible about the desired context, outcome, or length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is a new discipline that focuses on developing and optimizing prompts for language models (LMs) in order to improve their efficiency for various applications and research areas.\n",
      "Summary length in words: 29\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Summarize the text below in at most 50 words: \n",
    "Text: ```{text}```\n",
    "'''\n",
    "response = get_chat_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "print(f'Summary length in words: {len(response.split())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Tactic 3`: Use the RTF Format\n",
    "\n",
    "RTF = Role, Task, Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI assistant, I am here to provide you with safe and error-free commands. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "specific_role = 'Assistant' # Linux System Assistant\n",
    "update_system_role = '''You are an experienced {specific_role}. And will provide only safe and error-free commands.'''\n",
    "response = get_chat_completion(user_prompt=specific_role, system_role=update_system_role)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "  <title>Weekly Meal Plan for Weight Loss</title>\n",
      "</head>\n",
      "<body>\n",
      "  <h1>Weekly Meal Plan</h1>\n",
      "  <h2>Day 1</h2>\n",
      "  <h3>Breakfast: Avocado Egg Toast</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>1 slice whole wheat bread</li>\n",
      "      <li>1/4 ripe avocado, mashed</li>\n",
      "      <li>1 boiled egg, sliced</li>\n",
      "      <li>1 tsp olive oil</li>\n",
      "      <li>Salt and pepper to taste</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h3>Lunch: Grilled Chicken Salad</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>4 oz grilled chicken breast, sliced</li>\n",
      "      <li>2 cups mixed greens</li>\n",
      "      <li>1/2 cup cherry tomatoes</li>\n",
      "      <li>1/4 cup cucumber, sliced</li>\n",
      "      <li>1 tbsp olive oil and vinegar dressing</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h3>Dinner: Baked Lemon Herb Fish with Roasted Vegetables</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>4 oz white fish fillet</li>\n",
      "      <li>1 tbsp lemon juice</li>\n",
      "      <li>1 tsp dried herbs (such as rosemary or thyme)</li>\n",
      "      <li>1 cup assorted roasted vegetables (broccoli, bell peppers, carrots, etc.)</li>\n",
      "      <li>1 tsp olive oil</li>\n",
      "      <li>Salt and pepper to taste</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h2>Day 2</h2>\n",
      "  <h3>Breakfast: Green Smoothie</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>1 cup spinach</li>\n",
      "      <li>1/2 ripe avocado</li>\n",
      "      <li>1 small banana</li>\n",
      "      <li>1 cup unsweetened almond milk</li>\n",
      "      <li>1 tbsp honey or sweetener of your choice</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h3>Lunch: Chicken and Vegetable Stir-Fry</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>4 oz chicken breast, thinly sliced</li>\n",
      "      <li>1 cup mixed vegetables (bell peppers, broccoli, carrots, etc.)</li>\n",
      "      <li>1 tbsp low-sodium soy sauce</li>\n",
      "      <li>1 tsp olive oil</li>\n",
      "      <li>1/2 cup cooked brown rice</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h3>Dinner: Baked Herbed Chicken with Steamed Vegetables</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>4 oz chicken breast</li>\n",
      "      <li>1 tsp dried herbs (such as oregano or thyme)</li>\n",
      "      <li>1 cup steamed mixed vegetables (broccoli, cauliflower, zucchini, etc.)</li>\n",
      "      <li>1 tsp olive oil</li>\n",
      "      <li>Salt and pepper to taste</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h2>Day 3</h2>\n",
      "  <h3>Breakfast: Veggie Omelette</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>2 eggs</li>\n",
      "      <li>1/4 cup chopped vegetables (spinach, bell peppers, tomatoes, etc.)</li>\n",
      "      <li>1 tsp olive oil</li>\n",
      "      <li>Salt and pepper to taste</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h3>Lunch: Avocado Chicken Salad Wrap</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>4 oz cooked chicken breast, shredded</li>\n",
      "      <li>1/4 ripe avocado, mashed</li>\n",
      "      <li>1/4 cup diced tomatoes</li>\n",
      "      <li>1/4 cup diced cucumber</li>\n",
      "      <li>1 whole wheat wrap</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "\n",
      "  <h3>Dinner: Grilled Fish Tacos with Salsa Fresca</h3>\n",
      "  <p>\n",
      "    <ul>\n",
      "      <li>4 oz grilled white fish</li>\n",
      "      <li>2 whole wheat tortillas</li>\n",
      "      <li>1/4 cup salsa fresca (diced tomatoes, onions, cilantro, and lime juice)</li>\n",
      "      <li>1/4 cup shredded lettuce</li>\n",
      "      <li>1/4 ripe avocado, sliced</li>\n",
      "    </ul>\n",
      "  </p>\n",
      "  <!-- Repeat the above template for the remaining days of the week -->\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "system_role = 'Act like a chef with many years of experience in cooking healthy food'\n",
    "prompt = '''\n",
    "Write a weekly mean plan for weight loss. \n",
    "Keep it under 1800 cal per day\n",
    "Give title to the receipe.\n",
    "Use some of the following ingredients.\n",
    "Ingredients: ```\n",
    "- avocado\n",
    "- eggs\n",
    "- chicken breast\n",
    "- various vegetables\n",
    "- olive oil\n",
    "- fish\n",
    "```\n",
    "Format everything as HTML 5\n",
    "'''\n",
    "\n",
    "response = get_chat_completion(user_prompt=prompt, system_role=system_role)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "  <title>Weekly Meal Plan for Weight Loss</title>\n",
       "</head>\n",
       "<body>\n",
       "  <h1>Weekly Meal Plan</h1>\n",
       "  <h2>Day 1</h2>\n",
       "  <h3>Breakfast: Avocado Egg Toast</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>1 slice whole wheat bread</li>\n",
       "      <li>1/4 ripe avocado, mashed</li>\n",
       "      <li>1 boiled egg, sliced</li>\n",
       "      <li>1 tsp olive oil</li>\n",
       "      <li>Salt and pepper to taste</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h3>Lunch: Grilled Chicken Salad</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>4 oz grilled chicken breast, sliced</li>\n",
       "      <li>2 cups mixed greens</li>\n",
       "      <li>1/2 cup cherry tomatoes</li>\n",
       "      <li>1/4 cup cucumber, sliced</li>\n",
       "      <li>1 tbsp olive oil and vinegar dressing</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h3>Dinner: Baked Lemon Herb Fish with Roasted Vegetables</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>4 oz white fish fillet</li>\n",
       "      <li>1 tbsp lemon juice</li>\n",
       "      <li>1 tsp dried herbs (such as rosemary or thyme)</li>\n",
       "      <li>1 cup assorted roasted vegetables (broccoli, bell peppers, carrots, etc.)</li>\n",
       "      <li>1 tsp olive oil</li>\n",
       "      <li>Salt and pepper to taste</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h2>Day 2</h2>\n",
       "  <h3>Breakfast: Green Smoothie</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>1 cup spinach</li>\n",
       "      <li>1/2 ripe avocado</li>\n",
       "      <li>1 small banana</li>\n",
       "      <li>1 cup unsweetened almond milk</li>\n",
       "      <li>1 tbsp honey or sweetener of your choice</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h3>Lunch: Chicken and Vegetable Stir-Fry</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>4 oz chicken breast, thinly sliced</li>\n",
       "      <li>1 cup mixed vegetables (bell peppers, broccoli, carrots, etc.)</li>\n",
       "      <li>1 tbsp low-sodium soy sauce</li>\n",
       "      <li>1 tsp olive oil</li>\n",
       "      <li>1/2 cup cooked brown rice</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h3>Dinner: Baked Herbed Chicken with Steamed Vegetables</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>4 oz chicken breast</li>\n",
       "      <li>1 tsp dried herbs (such as oregano or thyme)</li>\n",
       "      <li>1 cup steamed mixed vegetables (broccoli, cauliflower, zucchini, etc.)</li>\n",
       "      <li>1 tsp olive oil</li>\n",
       "      <li>Salt and pepper to taste</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h2>Day 3</h2>\n",
       "  <h3>Breakfast: Veggie Omelette</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>2 eggs</li>\n",
       "      <li>1/4 cup chopped vegetables (spinach, bell peppers, tomatoes, etc.)</li>\n",
       "      <li>1 tsp olive oil</li>\n",
       "      <li>Salt and pepper to taste</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h3>Lunch: Avocado Chicken Salad Wrap</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>4 oz cooked chicken breast, shredded</li>\n",
       "      <li>1/4 ripe avocado, mashed</li>\n",
       "      <li>1/4 cup diced tomatoes</li>\n",
       "      <li>1/4 cup diced cucumber</li>\n",
       "      <li>1 whole wheat wrap</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "\n",
       "  <h3>Dinner: Grilled Fish Tacos with Salsa Fresca</h3>\n",
       "  <p>\n",
       "    <ul>\n",
       "      <li>4 oz grilled white fish</li>\n",
       "      <li>2 whole wheat tortillas</li>\n",
       "      <li>1/4 cup salsa fresca (diced tomatoes, onions, cilantro, and lime juice)</li>\n",
       "      <li>1/4 cup shredded lettuce</li>\n",
       "      <li>1/4 ripe avocado, sliced</li>\n",
       "    </ul>\n",
       "  </p>\n",
       "  <!-- Repeat the above template for the remaining days of the week -->\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a literary critic, I have carefully evaluated world literature and compiled a list of the top 10 books that I believe every teenager should read. Here is the list presented in JSON format:\n",
      "\n",
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"book_id\": 1,\n",
      "      \"title\": \"To Kill a Mockingbird\",\n",
      "      \"author\": \"Harper Lee\",\n",
      "      \"year\": 1960,\n",
      "      \"genre\": \"Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 2,\n",
      "      \"title\": \"1984\",\n",
      "      \"author\": \"George Orwell\",\n",
      "      \"year\": 1949,\n",
      "      \"genre\": \"Dystopian Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 3,\n",
      "      \"title\": \"The Catcher in the Rye\",\n",
      "      \"author\": \"J.D. Salinger\",\n",
      "      \"year\": 1951,\n",
      "      \"genre\": \"Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 4,\n",
      "      \"title\": \"Pride and Prejudice\",\n",
      "      \"author\": \"Jane Austen\",\n",
      "      \"year\": 1813,\n",
      "      \"genre\": \"Romance\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 5,\n",
      "      \"title\": \"To the Lighthouse\",\n",
      "      \"author\": \"Virginia Woolf\",\n",
      "      \"year\": 1927,\n",
      "      \"genre\": \"Modernist Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 6,\n",
      "      \"title\": \"Brave New World\",\n",
      "      \"author\": \"Aldous Huxley\",\n",
      "      \"year\": 1932,\n",
      "      \"genre\": \"Dystopian Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 7,\n",
      "      \"title\": \"The Great Gatsby\",\n",
      "      \"author\": \"F. Scott Fitzgerald\",\n",
      "      \"year\": 1925,\n",
      "      \"genre\": \"Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 8,\n",
      "      \"title\": \"Lord of the Flies\",\n",
      "      \"author\": \"William Golding\",\n",
      "      \"year\": 1954,\n",
      "      \"genre\": \"Fiction\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 9,\n",
      "      \"title\": \"The Hobbit\",\n",
      "      \"author\": \"J.R.R. Tolkien\",\n",
      "      \"year\": 1937,\n",
      "      \"genre\": \"Fantasy\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 10,\n",
      "      \"title\": \"The Diary of a Young Girl\",\n",
      "      \"author\": \"Anne Frank\",\n",
      "      \"year\": 1947,\n",
      "      \"genre\": \"Autobiography\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "These books have been chosen based on their literary merit, impact on literature, and ability to resonate with teenagers. Each book offers unique themes and perspectives, making them essential reads for any young reader.\n"
     ]
    }
   ],
   "source": [
    "system_role = 'Assume the role of a literary critic, carefully evaluating, studying and discussing literature'\n",
    "prompt = '''\n",
    "Analyse world literature and provide a list of the top 10 books a teenager should read. \n",
    "Present the output in JSON format with the following keys: book_id, title, author, year, and genre.\n",
    "'''\n",
    "\n",
    "response = get_chat_completion(user_prompt=prompt, system_role=system_role)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Tactic 4`: Few shot prompting\n",
    "\n",
    "* `Zero-Shot Prompting` - The user provides the LLM with a prompt, and th LLM tries to generate the output as well as it can (based on its understanding of the text provided). \n",
    "\n",
    "* `Few-Shot prompting` - The user provides the LLM with a few examples of the desired output, along with clear instructions and context. \n",
    "\n",
    "* `Fine-tuning` - Changing the base model to create a unique and differentiated experience for your users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love is a complex and profound emotion that humans have been trying to understand and define for centuries. It is experienced in various forms, including romantic love, familial love, and platonic love. Here are some key aspects to consider when learning about love:\n",
      "\n",
      "1. Love is a choice: Love is not just a feeling; it is an active choice that requires effort and commitment. It is a decision to prioritize the well-being and happiness of another person.\n",
      "\n",
      "2. Love is unconditional: True love is unconditional, which means it is not contingent on specific conditions or circumstances. It goes beyond superficial qualities or material possessions and accepts a person for who they truly are.\n",
      "\n",
      "3. Love requires vulnerability: To experience love deeply, it is necessary to open up and be vulnerable. Trust, honesty, and emotional intimacy are often crucial components of love.\n",
      "\n",
      "4. Love is not possessive: Love should not be about control or possessiveness. It is about allowing the other person to grow and thrive while offering support and encouragement.\n",
      "\n",
      "5. Love requires communication: Effective communication is essential for cultivating healthy and fulfilling relationships. It involves active listening, expressing emotions, and understanding each other's needs and desires.\n",
      "\n",
      "6. Love involves empathy and compassion: Love is about caring deeply for another person's well-being, understanding their perspective, and showing compassion in times of joy and hardship.\n",
      "\n",
      "7. Love evolves and grows: Love is not static; it evolves and grows over time. It requires nurturing, effort, and continuous willingness to adapt to changes in the relationship.\n",
      "\n",
      "8. Love involves self-love: Before being able to love others fully, it is important to cultivate self-love and self-acceptance. Taking care of your own well-being and being kind to yourself allows you to give and receive love more effectively.\n",
      "\n",
      "9. Love is not always easy: Love can be challenging. It involves compromise, understanding, and sometimes forgiving mistakes. It is important to be patient and committed during tough times to work through difficulties.\n",
      "\n",
      "10. Love is enriching: Love has the capacity to bring immense joy, fulfillment, and growth into our lives. It can provide a sense of purpose and connection that enhances our overall well-being.\n",
      "\n",
      "Remember that love is a unique and personal experience for each individual. It may look different for everyone, but the underlying principles of love remain constant. Embrace the journey of love with an open heart and an open mind, and allow yourself to learn, grow, and experience the depth and beauty it has to offer.\n"
     ]
    }
   ],
   "source": [
    "# Starting with zero-shot\n",
    "response = get_chat_completion('Teach me about love')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master]: Love is the gentlest touch in a storm; it is the warmth that persists amidst the coldest of nights; it is the beacon that guides lost souls home. Love is patient, kind, and everlasting.\n"
     ]
    }
   ],
   "source": [
    "# Few-shot: An example of a conversation between an apprentice and his/hers masters. \n",
    "prompt = '''\n",
    "You are an assistant that answers in a consistent manner. \n",
    "\n",
    "[apprentice]: Teach me about patience.\n",
    "\n",
    "[master]: The river that carves the deepest valley flows from a modest spring; \\\n",
    "the grandest symphny originates from a single not; \\\n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "[apprentice]: Teach me about love.\n",
    "'''\n",
    "response = get_chat_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
