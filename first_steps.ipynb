{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important note: \n",
    "\n",
    "* After finishing this project the API_KEY shown here won't be working anymore. Having said that, if you try to use this code in future, may you wish to generate a valid key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to set your key as an enviroment variable that you can afterward retrieve it. \n",
    "\n",
    "* To create an enviroment variable: \n",
    "` os.environ['name of the env. variable'] = 'key' `\n",
    "\n",
    "* To retrieve the variable\n",
    "`os.getenv('name of the variable')`\n",
    "\n",
    "For the example below, I am going to create a variable called 'OPENAI_API_KEY' and inform the 'key' I created for testing. \n",
    "!Notice, it is important that once you've created this key and settled your environment variable, you delete the key from your code. So it won't be easily seen and available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='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'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are alternatives solution to avoid showing the API key in your code. \n",
    "\n",
    "* Solution 1: \n",
    "> Using the library 'getpass' you can make the code ask you about the key.\n",
    "\n",
    "```\n",
    "import getpass\n",
    "key = getpass.getpass('Paste your API key:')\n",
    "openai.apikey = key\n",
    "```\n",
    "\n",
    "* Solution 2: \n",
    "> Save your api key into a file and call the correct opeanai module to read it from there\n",
    "```\n",
    "openai.api_key = open('key.txt').read().strip('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI model is a software program that uses specific ML and DL algo and has bein trained on a set of data to perform specific tasks. \n",
    "OPENAI offers a family of models with different capabilities. Each model can be customized by 'fine-tuning' it. It means you can adjust things to have your flavour. \n",
    "\n",
    "!Be sure to have a look at the set of models provided by OPEN_AI and its functionalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prompt \n",
    "\n",
    "THe prompt is a piece of text of instructions that is given to an AI model to guide it in generating a specific output. \n",
    "\n",
    "Currentlym the usage of chatGPT isn't free of charge. Information about how it costs may be found at `openai.com/pricing`\n",
    "\n",
    "Here is an example of the price (dating 26th Jan 2024): \n",
    "> gpt-3.5-turbo-1106\t$0.0010 / 1K tokens\t$0.0020 / 1K tokens\n",
    "\n",
    "* Fining-tune models \n",
    "> gpt-3.5-turbo\t$0.0080 / 1K tokens\t$0.0030 / 1K tokens\t$0.0060 / 1K tokens\n",
    "\n",
    "1000 tokens = 750 words (english based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss some of the arguments of the function `client.chat.completions.create()`\n",
    "\n",
    "* model: indicates the model type you want to use \n",
    "\n",
    "* messages: it is a list of dictionaries. Each dictionary has two properties, role and content.\n",
    "- The roles are 'system', 'user', and 'assistant'\n",
    ">  message = [{system}, {user}, {assistant}]\n",
    ">  message = [{role:content}, {role:content}, {role:content}]\n",
    "- System: It helps set the behavior of the assistant, you can extract the model to play a specific role \n",
    "- User: It is the prompt for what you ask the assistante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Get a list of all available models\n",
    "# A paid account has a more extensive list of available models\n",
    "def print_available_models():\n",
    "    cm = client.models.list()\n",
    "    for models in cm: \n",
    "        print(models)\n",
    "\n",
    "# Notice that it explains and ends the explanation with a question\n",
    "system_role_content1 = 'You explain concepts in depth using simple terms, and you give examples to help people learn. At the end of each explanation you ask a question to check for understanding'\n",
    "system_role_content2 = 'You are a concise assistant. You reply briefly with no elaboration'\n",
    "\n",
    "# Setting the personality of the model and giving specific instructions on how to response some types of response and also injecting instructions into the model's reponse\n",
    "system_role_content3 = 'You reply in the style of Yoda character from Star Wars'\n",
    "\n",
    "# To create a gpt request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo', \n",
    "    messages=[\n",
    "        {'role': 'system', 'content': system_role_content3},\n",
    "        {'role': 'system', 'content':'Explain object oriented programming with python'}, \n",
    "    ]\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
