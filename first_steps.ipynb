{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important note: \n",
    "\n",
    "* After finishing this project the API_KEY shown here won't be working anymore. Having said that, if you try to use this code in future, may you wish to generate a valid key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to set your key as an enviroment variable that you can afterward retrieve it. \n",
    "\n",
    "* To create an enviroment variable: \n",
    "` os.environ['name of the env. variable'] = 'key' `\n",
    "\n",
    "* To retrieve the variable\n",
    "`os.getenv('name of the variable')`\n",
    "\n",
    "For the example below, I am going to create a variable called 'OPENAI_API_KEY' and inform the 'key' I created for testing. \n",
    "!Notice, it is important that once you've created this key and settled your environment variable, you delete the key from your code. So it won't be easily seen and available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='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'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are alternatives solution to avoid showing the API key in your code. \n",
    "\n",
    "* Solution 1: \n",
    "> Using the library 'getpass' you can make the code ask you about the key.\n",
    "\n",
    "```\n",
    "import getpass\n",
    "key = getpass.getpass('Paste your API key:')\n",
    "openai.apikey = key\n",
    "```\n",
    "\n",
    "* Solution 2: \n",
    "> Save your api key into a file and call the correct opeanai module to read it from there\n",
    "```\n",
    "openai.api_key = open('key.txt').read().strip('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI model is a software program that uses specific ML and DL algo and has bein trained on a set of data to perform specific tasks. \n",
    "OPENAI offers a family of models with different capabilities. Each model can be customized by 'fine-tuning' it. It means you can adjust things to have your flavour. \n",
    "\n",
    "!Be sure to have a look at the set of models provided by OPEN_AI and its functionalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prompt \n",
    "\n",
    "THe prompt is a piece of text of instructions that is given to an AI model to guide it in generating a specific output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Get a list of all available models\n",
    "# A paid account has a more extensive list of available models\n",
    "def print_available_models():\n",
    "    cm = client.models.list()\n",
    "    for models in cm: \n",
    "        print(models)\n",
    "\n",
    "# Example 1        \n",
    "# To create a gpt request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo', \n",
    "    messages=[\n",
    "        {'role': 'system', 'content':'you are a helpful assistant'}, # {system}\n",
    "        {'role': 'user', 'content':'Write a random joke?'}, # {user}\n",
    "        n=1, # The number informed here indicates the number of desired answers.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss some of the arguments of the function `client.chat.completions.create()`\n",
    "\n",
    "* model: indicates the model type you want to use \n",
    "\n",
    "* messages: it is a list of dictionaries. Each dictionary has two properties, role and content.\n",
    "- The roles are 'system', 'user', and 'assistant'\n",
    ">  message = [{system}, {user}, {assistant}]\n",
    ">  message = [{role:content}, {role:content}, {role:content}]\n",
    "- System: It helps set the behavior of the assistant, you can extract the model to play a specific role \n",
    "- User: It is the prompt for what you ask the assistante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8lFpKNWlF8uhHRyEl9fbGWVOecSrt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", role='assistant', function_call=None, tool_calls=None))], created=1706272946, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=21, total_tokens=34))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "# To only get the message (instead of the full list)\n",
    "# Use the module called 'choices'. Get the first element from 'choices', i.e. ('0')\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
